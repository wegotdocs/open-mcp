# @open-mcp/api_humanloop_com_v5

## Installing

First set the environment variables as shell variables:

```bash
X_API_KEY='...'
```

Then use the OpenMCP config CLI to add the server to your MCP client:

### Claude desktop

```bash
npx @open-mcp/config add api_humanloop_com_v5 \
  ~/Library/Application\ Support/Claude/claude_desktop_config.json \
  --X_API_KEY=$X_API_KEY
```

### Cursor

Run this from the root of your project directory or, to add to all cursor projects, run it from your home directory `~`.

```bash
npx @open-mcp/config add api_humanloop_com_v5 \
  .cursor/mcp.json \
  --X_API_KEY=$X_API_KEY
```

### Other

```bash
npx @open-mcp/config add api_humanloop_com_v5 \
  /path/to/client/config.json \
  --X_API_KEY=$X_API_KEY
```

### Manually

If you don't want to use the helper above, add the following to your MCP client config manually:

```json
{
  "mcpServers": {
    "api_humanloop_com_v5": {
      "command": "npx",
      "args": ["-y", "@open-mcp/api_humanloop_com_v5"],
      "env": {"X_API_KEY":"..."}
    }
  }
}
```

## Customizing the base URL

Set the environment variable `OPEN_MCP_BASE_URL` to override each tool's base URL. This is useful if your OpenAPI spec defines a relative server URL.

## Other environment variables

- `X_API_KEY`

## Inspector

Needs access to port 3000 for running a proxy server, will fail if http://localhost:3000 is already busy.

```bash
npx -y @modelcontextprotocol/inspector npx -y @open-mcp/api_humanloop_com_v5
```

- Open http://localhost:5173
- Transport type: `STDIO`
- Command: `npx`
- Arguments: `-y @open-mcp/api_humanloop_com_v5`
- Click `Environment Variables` to add
- Click `Connect`

It should say _MCP Server running on stdio_ in red.

- Click `List Tools`

## Tools

### expandSchema

Expand the input schema for a tool before calling the tool

**Input schema**

```ts
{
  toolName: z.string(),
  jsonPointers: z.array(z.string().startsWith("/").describe("The pointer to the JSON schema object which needs expanding")).describe("A list of JSON pointers"),
}
```

### log_prompts_log_post

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "version_id": z.string().describe("A specific Version ID of the Prompt to log to.").optional(),
  "environment": z.string().describe("Name of the Environment identifying a deployed version to log to.").optional(),
  "run_id": z.string().describe("Unique identifier for the Run to associate the Log to.").optional(),
  "path": z.string().describe("Path of the Prompt, including the name. This locates the Prompt in the Humanloop filesystem and is used as as a unique identifier. For example: \`folder/name\` or just \`name\`.").optional(),
  "id": z.string().describe("ID for an existing Prompt.").optional(),
  "output_message": z.string().optional(),
  "prompt_tokens": z.number().int().describe("Number of tokens in the prompt used to generate the output.").optional(),
  "reasoning_tokens": z.number().int().describe("Number of reasoning tokens used to generate the output.").optional(),
  "output_tokens": z.number().int().describe("Number of tokens in the output generated by the model.").optional(),
  "prompt_cost": z.number().describe("Cost in dollars associated to the tokens in the prompt.").optional(),
  "output_cost": z.number().describe("Cost in dollars associated to the tokens in the output.").optional(),
  "finish_reason": z.string().describe("Reason the generation finished.").optional(),
  "messages": z.array(z.object({ "content": z.union([z.string(), z.array(z.union([z.object({ "type": z.literal("text"), "text": z.string().describe("The message's text content.") }), z.object({ "type": z.literal("image_url"), "image_url": z.string() })]))]).nullable().describe("The content of the message.").optional(), "name": z.string().nullable().describe("Optional name of the message author.").optional(), "tool_call_id": z.string().nullable().describe("Tool call that this message is responding to.").optional(), "role": z.string(), "tool_calls": z.array(z.object({ "id": z.string(), "type": z.literal("function").describe("The type of tool to call."), "function": z.object({ "name": z.string(), "arguments": z.string().optional() }).describe("A function tool to be called by the model where user owns runtime.") }).describe("A tool call to be made.")).nullable().describe("A list of tool calls requested by the assistant.").optional() })).describe("The messages passed to the to provider chat endpoint.").optional(),
  "tool_choice": z.union([z.literal("none"), z.literal("auto"), z.literal("required"), z.object({ "type": z.literal("function").describe("The type of tool to call."), "function": z.object({ "name": z.string() }).describe("A function tool to be called by the model where user owns runtime.") }).describe("Tool choice to force the model to use a tool.")]).describe("Controls how the model uses tools. The following options are supported: \n- \`'none'\` means the model will not call any tool and instead generates a message; this is the default when no tools are provided as part of the Prompt. \n- \`'auto'\` means the model can decide to call one or more of the provided tools; this is the default when tools are provided as part of the Prompt. \n- \`'required'\` means the model must call one or more of the provided tools. \n- \`{'type': 'function', 'function': {name': <TOOL_NAME>}}\` forces the model to use the named function.").optional(),
  "prompt": z.string().optional(),
  "start_time": z.string().datetime({ offset: true }).describe("When the logged event started.").optional(),
  "end_time": z.string().datetime({ offset: true }).describe("When the logged event ended.").optional(),
  "output": z.string().describe("Generated output from your model for the provided inputs. Can be \`None\` if logging an error, or if creating a parent Log with the intention to populate it later.").optional(),
  "created_at": z.string().datetime({ offset: true }).describe("User defined timestamp for when the log was created. ").optional(),
  "error": z.string().describe("Error message if the log is an error.").optional(),
  "provider_latency": z.number().describe("Duration of the logged event in seconds.").optional(),
  "stdout": z.string().describe("Captured log and debug statements.").optional(),
  "provider_request": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nRaw request sent to provider.").optional(),
  "provider_response": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nRaw response received the provider.").optional(),
  "inputs": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nThe inputs passed to the prompt template.").optional(),
  "source": z.string().describe("Identifies where the model was called from.").optional(),
  "metadata": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nAny additional metadata to record.").optional(),
  "log_status": z.string().optional(),
  "source_datapoint_id": z.string().describe("Unique identifier for the Datapoint that this Log is derived from. This can be used by Humanloop to associate Logs to Evaluations. If provided, Humanloop will automatically associate this Log to Evaluations that require a Log for this Datapoint-Version pair.").optional(),
  "trace_parent_id": z.string().describe("The ID of the parent Log to nest this Log under in a Trace.").optional(),
  "user": z.string().describe("End-user ID related to the Log.").optional(),
  "b_environment": z.string().describe("The name of the Environment the Log is associated to.").optional(),
  "save": z.boolean().describe("Whether the request/response payloads will be stored on Humanloop.").optional(),
  "log_id": z.string().describe("This will identify a Log. If you don't provide a Log ID, Humanloop will generate one for you.").optional()
}
```

### update_log_prompts_id_log_log_id_patch

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Prompt."),
  "log_id": z.string().describe("Unique identifier for the Log."),
  "output_message": z.string().optional(),
  "prompt_tokens": z.number().int().describe("Number of tokens in the prompt used to generate the output.").optional(),
  "reasoning_tokens": z.number().int().describe("Number of reasoning tokens used to generate the output.").optional(),
  "output_tokens": z.number().int().describe("Number of tokens in the output generated by the model.").optional(),
  "prompt_cost": z.number().describe("Cost in dollars associated to the tokens in the prompt.").optional(),
  "output_cost": z.number().describe("Cost in dollars associated to the tokens in the output.").optional(),
  "finish_reason": z.string().describe("Reason the generation finished.").optional(),
  "messages": z.array(z.object({ "content": z.union([z.string(), z.array(z.union([z.object({ "type": z.literal("text"), "text": z.string().describe("The message's text content.") }), z.object({ "type": z.literal("image_url"), "image_url": z.string() })]))]).nullable().describe("The content of the message.").optional(), "name": z.string().nullable().describe("Optional name of the message author.").optional(), "tool_call_id": z.string().nullable().describe("Tool call that this message is responding to.").optional(), "role": z.string(), "tool_calls": z.array(z.object({ "id": z.string(), "type": z.literal("function").describe("The type of tool to call."), "function": z.object({ "name": z.string(), "arguments": z.string().optional() }).describe("A function tool to be called by the model where user owns runtime.") }).describe("A tool call to be made.")).nullable().describe("A list of tool calls requested by the assistant.").optional() })).describe("The messages passed to the to provider chat endpoint.").optional(),
  "tool_choice": z.union([z.literal("none"), z.literal("auto"), z.literal("required"), z.object({ "type": z.literal("function").describe("The type of tool to call."), "function": z.object({ "name": z.string() }).describe("A function tool to be called by the model where user owns runtime.") }).describe("Tool choice to force the model to use a tool.")]).describe("Controls how the model uses tools. The following options are supported: \n- \`'none'\` means the model will not call any tool and instead generates a message; this is the default when no tools are provided as part of the Prompt. \n- \`'auto'\` means the model can decide to call one or more of the provided tools; this is the default when tools are provided as part of the Prompt. \n- \`'required'\` means the model must call one or more of the provided tools. \n- \`{'type': 'function', 'function': {name': <TOOL_NAME>}}\` forces the model to use the named function.").optional(),
  "output": z.string().describe("Generated output from your model for the provided inputs. Can be \`None\` if logging an error, or if creating a parent Log with the intention to populate it later.").optional(),
  "created_at": z.string().datetime({ offset: true }).describe("User defined timestamp for when the log was created. ").optional(),
  "error": z.string().describe("Error message if the log is an error.").optional(),
  "provider_latency": z.number().describe("Duration of the logged event in seconds.").optional(),
  "stdout": z.string().describe("Captured log and debug statements.").optional(),
  "provider_request": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nRaw request sent to provider.").optional(),
  "provider_response": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nRaw response received the provider.").optional(),
  "inputs": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nThe inputs passed to the prompt template.").optional(),
  "source": z.string().describe("Identifies where the model was called from.").optional(),
  "metadata": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nAny additional metadata to record.").optional(),
  "start_time": z.string().datetime({ offset: true }).describe("When the logged event started.").optional(),
  "end_time": z.string().datetime({ offset: true }).describe("When the logged event ended.").optional(),
  "log_status": z.string().optional()
}
```

### call_prompts_call_post

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "version_id": z.string().describe("A specific Version ID of the Prompt to log to.").optional(),
  "environment": z.string().describe("Name of the Environment identifying a deployed version to log to.").optional(),
  "path": z.string().describe("Path of the Prompt, including the name. This locates the Prompt in the Humanloop filesystem and is used as as a unique identifier. For example: \`folder/name\` or just \`name\`.").optional(),
  "id": z.string().describe("ID for an existing Prompt.").optional(),
  "messages": z.array(z.object({ "content": z.union([z.string(), z.array(z.union([z.object({ "type": z.literal("text"), "text": z.string().describe("The message's text content.") }), z.object({ "type": z.literal("image_url"), "image_url": z.string() })]))]).nullable().describe("The content of the message.").optional(), "name": z.string().nullable().describe("Optional name of the message author.").optional(), "tool_call_id": z.string().nullable().describe("Tool call that this message is responding to.").optional(), "role": z.string(), "tool_calls": z.array(z.object({ "id": z.string(), "type": z.literal("function").describe("The type of tool to call."), "function": z.object({ "name": z.string(), "arguments": z.string().optional() }).describe("A function tool to be called by the model where user owns runtime.") }).describe("A tool call to be made.")).nullable().describe("A list of tool calls requested by the assistant.").optional() })).describe("The messages passed to the to provider chat endpoint.").optional(),
  "tool_choice": z.union([z.literal("none"), z.literal("auto"), z.literal("required"), z.object({ "type": z.literal("function").describe("The type of tool to call."), "function": z.object({ "name": z.string() }).describe("A function tool to be called by the model where user owns runtime.") }).describe("Tool choice to force the model to use a tool.")]).describe("Controls how the model uses tools. The following options are supported: \n- \`'none'\` means the model will not call any tool and instead generates a message; this is the default when no tools are provided as part of the Prompt. \n- \`'auto'\` means the model can decide to call one or more of the provided tools; this is the default when tools are provided as part of the Prompt. \n- \`'required'\` means the model must call one or more of the provided tools. \n- \`{'type': 'function', 'function': {name': <TOOL_NAME>}}\` forces the model to use the named function.").optional(),
  "prompt": z.string().optional(),
  "inputs": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nThe inputs passed to the prompt template.").optional(),
  "source": z.string().describe("Identifies where the model was called from.").optional(),
  "metadata": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nAny additional metadata to record.").optional(),
  "start_time": z.string().datetime({ offset: true }).describe("When the logged event started.").optional(),
  "end_time": z.string().datetime({ offset: true }).describe("When the logged event ended.").optional(),
  "log_status": z.string().optional(),
  "source_datapoint_id": z.string().describe("Unique identifier for the Datapoint that this Log is derived from. This can be used by Humanloop to associate Logs to Evaluations. If provided, Humanloop will automatically associate this Log to Evaluations that require a Log for this Datapoint-Version pair.").optional(),
  "trace_parent_id": z.string().describe("The ID of the parent Log to nest this Log under in a Trace.").optional(),
  "user": z.string().describe("End-user ID related to the Log.").optional(),
  "b_environment": z.string().describe("The name of the Environment the Log is associated to.").optional(),
  "save": z.boolean().describe("Whether the request/response payloads will be stored on Humanloop.").optional(),
  "log_id": z.string().describe("This will identify a Log. If you don't provide a Log ID, Humanloop will generate one for you.").optional(),
  "provider_api_keys": z.string().optional(),
  "num_samples": z.number().int().describe("The number of generations.").optional(),
  "stream": z.boolean().describe("If true, tokens will be sent as data-only server-sent events. If num_samples > 1, samples are streamed back independently.").optional(),
  "return_inputs": z.boolean().describe("Whether to return the inputs in the response. If false, the response will contain an empty dictionary under inputs. This is useful for reducing the size of the response. Defaults to true.").optional(),
  "logprobs": z.number().int().describe("Include the log probabilities of the top n tokens in the provider_response").optional(),
  "suffix": z.string().describe("The suffix that comes after a completion of inserted text. Useful for completions that act like inserts.").optional()
}
```

### list_prompts_get

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "page": z.number().int().gte(1).describe("Page number for pagination.").optional(),
  "size": z.number().int().gte(0).describe("Page size for pagination. Number of Prompts to fetch.").optional(),
  "name": z.string().describe("Case-insensitive filter for Prompt name.").optional(),
  "user_filter": z.string().describe("Case-insensitive filter for users in the Prompt. This filter matches against both email address and name of users.").optional(),
  "sort_by": z.enum(["created_at","updated_at","name"]).describe("An enumeration.").describe("Field to sort Prompts by").optional(),
  "order": z.enum(["asc","desc"]).describe("An enumeration.").describe("Direction to sort by.").optional()
}
```

### upsert_prompts_post

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "path": z.string().describe("Path of the Prompt, including the name. This locates the Prompt in the Humanloop filesystem and is used as as a unique identifier. For example: \`folder/name\` or just \`name\`.").optional(),
  "id": z.string().describe("ID for an existing Prompt.").optional(),
  "model": z.string().describe("The model instance used, e.g. \`gpt-4\`. See [supported models](https://humanloop.com/docs/reference/supported-models)"),
  "endpoint": z.string().optional(),
  "template": z.union([z.string(), z.array(z.object({ "content": z.union([z.string(), z.array(z.union([z.object({ "type": z.literal("text"), "text": z.string().describe("The message's text content.") }), z.object({ "type": z.literal("image_url"), "image_url": z.string() })]))]).nullable().describe("The content of the message.").optional(), "name": z.string().nullable().describe("Optional name of the message author.").optional(), "tool_call_id": z.string().nullable().describe("Tool call that this message is responding to.").optional(), "role": z.string(), "tool_calls": z.array(z.object({ "id": z.string(), "type": z.literal("function").describe("The type of tool to call."), "function": z.object({ "name": z.string(), "arguments": z.string().optional() }).describe("A function tool to be called by the model where user owns runtime.") }).describe("A tool call to be made.")).nullable().describe("A list of tool calls requested by the assistant.").optional() }))]).describe("The template contains the main structure and instructions for the model, including input variables for dynamic values. \n\nFor chat models, provide the template as a ChatTemplate (a list of messages), e.g. a system message, followed by a user message with an input variable.\nFor completion models, provide a prompt template as a string. \n\nInput variables should be specified with double curly bracket syntax: \`{{input_name}}\`.").optional(),
  "template_language": z.string().optional(),
  "provider": z.string().optional(),
  "max_tokens": z.number().int().describe("The maximum number of tokens to generate. Provide max_tokens=-1 to dynamically calculate the maximum number of tokens to generate given the length of the prompt").optional(),
  "temperature": z.number().describe("What sampling temperature to use when making a generation. Higher values means the model will be more creative.").optional(),
  "top_p": z.number().describe("An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass.").optional(),
  "stop": z.union([z.string(), z.array(z.string())]).describe("The string (or list of strings) after which the model will stop generating. The returned text will not contain the stop sequence.").optional(),
  "presence_penalty": z.number().describe("Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the generation so far.").optional(),
  "frequency_penalty": z.number().describe("Number between -2.0 and 2.0. Positive values penalize new tokens based on how frequently they appear in the generation so far.").optional(),
  "other": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nOther parameter values to be passed to the provider call.").optional(),
  "seed": z.number().int().describe("If specified, model will make a best effort to sample deterministically, but it is not guaranteed.").optional(),
  "response_format": z.string().optional(),
  "reasoning_effort": z.string().optional(),
  "tools": z.array(z.object({ "name": z.string().describe("Name for the tool referenced by the model."), "description": z.string().describe("Description of the tool referenced by the model"), "strict": z.boolean().describe("If true, forces the model to output json data in the structure of the parameters schema."), "parameters": z.record(z.any()).describe("Parameters needed to run the Tool, defined in JSON Schema format: https://json-schema.org/").optional() })).describe("The tool specification that the model can choose to call if Tool calling is supported.").optional(),
  "linked_tools": z.array(z.string()).describe("The IDs of the Tools in your organization that the model can choose to call if Tool calling is supported. The default deployed version of that tool is called.").optional(),
  "attributes": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nAdditional fields to describe the Prompt. Helpful to separate Prompt versions from each other with details on how they were created or used.").optional(),
  "version_name": z.string().describe("Unique name for the Prompt version. Version names must be unique for a given Prompt.").optional(),
  "version_description": z.string().describe("Description of the version, e.g., the changes made in this version.").optional(),
  "description": z.string().describe("Description of the Prompt.").optional(),
  "tags": z.array(z.string()).describe("List of tags associated with this prompt.").optional(),
  "readme": z.string().describe("Long description of the Prompt.").optional()
}
```

### get_prompts_id_get

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Prompt."),
  "version_id": z.string().describe("A specific Version ID of the Prompt to retrieve.").optional(),
  "environment": z.string().describe("Name of the Environment to retrieve a deployed Version from.").optional()
}
```

### delete_prompts_id_delete

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Prompt.")
}
```

### move_prompts_id_patch

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Prompt."),
  "path": z.string().describe("Path of the Prompt including the Prompt name, which is used as a unique identifier.").optional(),
  "name": z.string().describe("Name of the Prompt.").optional()
}
```

### populate_prompts_id_populate_post

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Prompt."),
  "version_id": z.string().describe("A specific Version ID of the Prompt to retrieve to populate the template.").optional(),
  "environment": z.string().describe("Name of the Environment to retrieve a deployed Version from to populate the template.").optional()
}
```

### list_versions_prompts_id_versions_get

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Prompt."),
  "evaluator_aggregates": z.boolean().describe("Whether to include Evaluator aggregate results for the versions in the response").optional()
}
```

### delete_prompt_version_prompts_id_versions_version_id_delete

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Prompt."),
  "version_id": z.string().describe("Unique identifier for the specific version of the Prompt.")
}
```

### patch_prompt_version_prompts_id_versions_version_id_patch

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Prompt."),
  "version_id": z.string().describe("Unique identifier for the specific version of the Prompt."),
  "name": z.string().describe("Name of the version.").optional(),
  "description": z.string().describe("Description of the version.").optional()
}
```

### set_deployment_prompts_id_environments_environment_id_post

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Prompt."),
  "environment_id": z.string().describe("Unique identifier for the Environment to deploy the Version to."),
  "version_id": z.string().describe("Unique identifier for the specific version of the Prompt.")
}
```

### remove_deployment_prompts_id_environments_environment_id_delete

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Prompt."),
  "environment_id": z.string().describe("Unique identifier for the Environment to remove the deployment from.")
}
```

### list_environments_prompts_id_environments_get

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Prompt.")
}
```

### update_monitoring_prompts_id_evaluators_post

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string(),
  "activate": z.array(z.union([z.object({ "evaluator_version_id": z.string().describe("Unique identifier for the Evaluator Version to be used for monitoring.") }), z.object({ "evaluator_id": z.string().describe("Unique identifier for the Evaluator to be used for monitoring."), "environment_id": z.string().describe("Unique identifier for the Environment. The Evaluator Version deployed to this Environment will be used for monitoring.") })])).describe("Evaluators to activate for Monitoring. These will be automatically run on new Logs.").optional(),
  "deactivate": z.array(z.union([z.object({ "evaluator_version_id": z.string().describe("Unique identifier for the Evaluator Version to be used for monitoring.") }), z.object({ "evaluator_id": z.string().describe("Unique identifier for the Evaluator to be used for monitoring."), "environment_id": z.string().describe("Unique identifier for the Environment. The Evaluator Version deployed to this Environment will be used for monitoring.") })])).describe("Evaluators to deactivate. These will not be run on new Logs.").optional()
}
```

### log_tools_log_post

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "version_id": z.string().describe("A specific Version ID of the Tool to log to.").optional(),
  "environment": z.string().describe("Name of the Environment identifying a deployed version to log to.").optional(),
  "path": z.string().describe("Path of the Tool, including the name. This locates the Tool in the Humanloop filesystem and is used as as a unique identifier. For example: \`folder/name\` or just \`name\`.").optional(),
  "id": z.string().describe("ID for an existing Tool.").optional(),
  "start_time": z.string().datetime({ offset: true }).describe("When the logged event started.").optional(),
  "end_time": z.string().datetime({ offset: true }).describe("When the logged event ended.").optional(),
  "output": z.string().describe("Generated output from your model for the provided inputs. Can be \`None\` if logging an error, or if creating a parent Log with the intention to populate it later.").optional(),
  "created_at": z.string().datetime({ offset: true }).describe("User defined timestamp for when the log was created. ").optional(),
  "error": z.string().describe("Error message if the log is an error.").optional(),
  "provider_latency": z.number().describe("Duration of the logged event in seconds.").optional(),
  "stdout": z.string().describe("Captured log and debug statements.").optional(),
  "provider_request": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nRaw request sent to provider.").optional(),
  "provider_response": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nRaw response received the provider.").optional(),
  "inputs": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nThe inputs passed to the prompt template.").optional(),
  "source": z.string().describe("Identifies where the model was called from.").optional(),
  "metadata": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nAny additional metadata to record.").optional(),
  "log_status": z.string().optional(),
  "source_datapoint_id": z.string().describe("Unique identifier for the Datapoint that this Log is derived from. This can be used by Humanloop to associate Logs to Evaluations. If provided, Humanloop will automatically associate this Log to Evaluations that require a Log for this Datapoint-Version pair.").optional(),
  "trace_parent_id": z.string().describe("The ID of the parent Log to nest this Log under in a Trace.").optional(),
  "user": z.string().describe("End-user ID related to the Log.").optional(),
  "b_environment": z.string().describe("The name of the Environment the Log is associated to.").optional(),
  "save": z.boolean().describe("Whether the request/response payloads will be stored on Humanloop.").optional(),
  "log_id": z.string().describe("This will identify a Log. If you don't provide a Log ID, Humanloop will generate one for you.").optional(),
  "tool": z.string().optional()
}
```

### tools_update

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Prompt."),
  "log_id": z.string().describe("Unique identifier for the Log."),
  "output": z.string().describe("Generated output from your model for the provided inputs. Can be \`None\` if logging an error, or if creating a parent Log with the intention to populate it later.").optional(),
  "created_at": z.string().datetime({ offset: true }).describe("User defined timestamp for when the log was created. ").optional(),
  "error": z.string().describe("Error message if the log is an error.").optional(),
  "provider_latency": z.number().describe("Duration of the logged event in seconds.").optional(),
  "stdout": z.string().describe("Captured log and debug statements.").optional(),
  "provider_request": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nRaw request sent to provider.").optional(),
  "provider_response": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nRaw response received the provider.").optional(),
  "inputs": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nThe inputs passed to the prompt template.").optional(),
  "source": z.string().describe("Identifies where the model was called from.").optional(),
  "metadata": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nAny additional metadata to record.").optional(),
  "start_time": z.string().datetime({ offset: true }).describe("When the logged event started.").optional(),
  "end_time": z.string().datetime({ offset: true }).describe("When the logged event ended.").optional(),
  "log_status": z.string().optional()
}
```

### list_tools_get

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "page": z.number().int().gte(1).describe("Page offset for pagination.").optional(),
  "size": z.number().int().describe("Page size for pagination. Number of Tools to fetch.").optional(),
  "name": z.string().describe("Case-insensitive filter for Tool name.").optional(),
  "user_filter": z.string().describe("Case-insensitive filter for users in the Tool. This filter matches against both email address and name of users.").optional(),
  "sort_by": z.enum(["created_at","updated_at","name"]).describe("An enumeration.").describe("Field to sort Tools by").optional(),
  "order": z.enum(["asc","desc"]).describe("An enumeration.").describe("Direction to sort by.").optional()
}
```

### upsert_tools_post

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "path": z.string().describe("Path of the Tool, including the name. This locates the Tool in the Humanloop filesystem and is used as as a unique identifier. For example: \`folder/name\` or just \`name\`.").optional(),
  "id": z.string().describe("ID for an existing Tool.").optional(),
  "function": z.string().optional(),
  "source_code": z.string().describe("Code source of the Tool.").optional(),
  "setup_values": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nValues needed to setup the Tool, defined in JSON Schema format: https://json-schema.org/").optional(),
  "attributes": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nAdditional fields to describe the Tool. Helpful to separate Tool versions from each other with details on how they were created or used.").optional(),
  "tool_type": z.string().optional(),
  "version_name": z.string().describe("Unique identifier for this Tool version. Each Tool can only have one version with a given name.").optional(),
  "version_description": z.string().describe("Description of the Version.").optional()
}
```

### get_tools_id_get

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Tool."),
  "version_id": z.string().describe("A specific Version ID of the Tool to retrieve.").optional(),
  "environment": z.string().describe("Name of the Environment to retrieve a deployed Version from.").optional()
}
```

### delete_tools_id_delete

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Tool.")
}
```

### move_tools_id_patch

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Tool."),
  "path": z.string().describe("Path of the Tool including the Tool name, which is used as a unique identifier.").optional(),
  "name": z.string().describe("Name of the Tool, which is used as a unique identifier.").optional()
}
```

### list_versions_tools_id_versions_get

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for the Tool."),
  "evaluator_aggregates": z.boolean().describe("Whether to include Evaluator aggregate results for the versions in the response").optional()
}
```

### delete_tool_version_tools_id_versions_version_id_delete

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Tool."),
  "version_id": z.string().describe("Unique identifier for the specific version of the Tool.")
}
```

### update_tool_version_tools_id_versions_version_id_patch

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Tool."),
  "version_id": z.string().describe("Unique identifier for the specific version of the Tool."),
  "name": z.string().describe("Name of the version.").optional(),
  "description": z.string().describe("Description of the version.").optional()
}
```

### set_deployment_tools_id_environments_environment_id_post

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Tool."),
  "environment_id": z.string().describe("Unique identifier for the Environment to deploy the Version to."),
  "version_id": z.string().describe("Unique identifier for the specific version of the Tool.")
}
```

### remove_deployment_tools_id_environments_environment_id_delete

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Tool."),
  "environment_id": z.string().describe("Unique identifier for the Environment to remove the deployment from.")
}
```

### list_environments_tools_id_environments_get

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Tool.")
}
```

### update_monitoring_tools_id_evaluators_post

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string(),
  "activate": z.array(z.union([z.object({ "evaluator_version_id": z.string().describe("Unique identifier for the Evaluator Version to be used for monitoring.") }), z.object({ "evaluator_id": z.string().describe("Unique identifier for the Evaluator to be used for monitoring."), "environment_id": z.string().describe("Unique identifier for the Environment. The Evaluator Version deployed to this Environment will be used for monitoring.") })])).describe("Evaluators to activate for Monitoring. These will be automatically run on new Logs.").optional(),
  "deactivate": z.array(z.union([z.object({ "evaluator_version_id": z.string().describe("Unique identifier for the Evaluator Version to be used for monitoring.") }), z.object({ "evaluator_id": z.string().describe("Unique identifier for the Evaluator to be used for monitoring."), "environment_id": z.string().describe("Unique identifier for the Environment. The Evaluator Version deployed to this Environment will be used for monitoring.") })])).describe("Evaluators to deactivate. These will not be run on new Logs.").optional()
}
```

### list_datasets_get

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "page": z.number().int().gte(1).describe("Page offset for pagination.").optional(),
  "size": z.number().int().gte(0).describe("Page size for pagination. Number of Datasets to fetch.").optional(),
  "name": z.string().describe("Case-insensitive filter for Dataset name.").optional(),
  "user_filter": z.string().describe("Case-insensitive filter for users in the Dataset. This filter matches against both email address and name of users.").optional(),
  "sort_by": z.enum(["created_at","updated_at","name"]).describe("An enumeration.").describe("Field to sort Datasets by").optional(),
  "order": z.enum(["asc","desc"]).describe("An enumeration.").describe("Direction to sort by.").optional()
}
```

### upsert_datasets_post

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "version_id": z.string().describe("ID of the specific Dataset version to base the created Version on. Only used when \`action\` is \`\"add\"\` or \`\"remove\"\`.").optional(),
  "environment": z.string().describe("Name of the Environment identifying a deployed Version to base the created Version on. Only used when \`action\` is \`\"add\"\` or \`\"remove\"\`.").optional(),
  "include_datapoints": z.boolean().describe("If set to \`true\`, include all Datapoints in the response. Defaults to \`false\`. Consider using the paginated List Datapoints endpoint instead.").optional(),
  "path": z.string().describe("Path of the Dataset, including the name. This locates the Dataset in the Humanloop filesystem and is used as as a unique identifier. For example: \`folder/name\` or just \`name\`.").optional(),
  "id": z.string().describe("ID for an existing Dataset.").optional(),
  "datapoints": z.array(z.object({ "inputs": z.record(z.string()).describe("The inputs to the prompt template."), "messages": z.array(z.object({ "content": z.union([z.string(), z.array(z.union([z.object({ "type": z.literal("text"), "text": z.string().describe("The message's text content.") }), z.object({ "type": z.literal("image_url"), "image_url": z.string() })]))]).nullable().describe("The content of the message.").optional(), "name": z.string().nullable().describe("Optional name of the message author.").optional(), "tool_call_id": z.string().nullable().describe("Tool call that this message is responding to.").optional(), "role": z.string(), "tool_calls": z.array(z.object({ "id": z.string(), "type": z.literal("function").describe("The type of tool to call."), "function": z.object({ "name": z.string(), "arguments": z.string().optional() }).describe("A function tool to be called by the model where user owns runtime.") }).describe("A tool call to be made.")).nullable().describe("A list of tool calls requested by the assistant.").optional() })).describe("List of chat messages to provide to the model.").optional(), "target": z.record(z.union([z.string(), z.number().int(), z.number(), z.boolean(), z.array(z.any()), z.record(z.any())])).describe("Object with criteria necessary to evaluate generations with this Datapoint. This is passed in as an argument to Evaluators when used in an Evaluation.").optional() })).describe("The Datapoints to create this Dataset version with. Modify the \`action\` field to determine how these Datapoints are used."),
  "action": z.string().optional(),
  "attributes": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nAdditional fields to describe the Dataset. Helpful to separate Dataset versions from each other with details on how they were created or used.").optional(),
  "version_name": z.string().describe("Unique name for the Dataset version. Version names must be unique for a given Dataset.").optional(),
  "version_description": z.string().describe("Description of the version, e.g., the changes made in this version.").optional()
}
```

### get_datasets_id_get

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Dataset."),
  "version_id": z.string().describe("A specific Version ID of the Dataset to retrieve.").optional(),
  "environment": z.string().describe("Name of the Environment to retrieve a deployed Version from.").optional(),
  "include_datapoints": z.boolean().describe("If set to \`true\`, include all Datapoints in the response. Defaults to \`false\`. Consider using the paginated List Datapoints endpoint instead.").optional()
}
```

### delete_datasets_id_delete

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Dataset.")
}
```

### move_datasets_id_patch

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Dataset."),
  "path": z.string().describe("Path of the Dataset including the Dataset name, which is used as a unique identifier.").optional(),
  "name": z.string().describe("Name of the Dataset, which is used as a unique identifier.").optional()
}
```

### list_datapoints_datasets_id_datapoints_get

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Dataset."),
  "version_id": z.string().describe("A specific Version ID of the Dataset to retrieve.").optional(),
  "environment": z.string().describe("Name of the Environment to retrieve a deployed Version from.").optional(),
  "page": z.number().int().gte(1).describe("Page number for pagination.").optional(),
  "size": z.number().int().gte(0).describe("Page size for pagination. Number of Datapoints to fetch.").optional()
}
```

### list_versions_datasets_id_versions_get

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Dataset."),
  "include_datapoints": z.enum(["latest_committed","latest_saved"]).describe("If set to 'latest_saved', include datapoints for the latest saved version. Alternatively, 'latest_committed' (deprecated) includes datapoints for the latest committed version only.").optional()
}
```

### delete_dataset_version_datasets_id_versions_version_id_delete

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Dataset."),
  "version_id": z.string().describe("Unique identifier for the specific version of the Dataset.")
}
```

### update_dataset_version_datasets_id_versions_version_id_patch

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Dataset."),
  "version_id": z.string().describe("Unique identifier for the specific version of the Dataset."),
  "name": z.string().describe("Name of the version.").optional(),
  "description": z.string().describe("Description of the version.").optional()
}
```

### upload_csv_datasets_id_datapoints_csv_post

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for the Dataset"),
  "version_id": z.string().describe("ID of the specific Dataset version to base the created Version on.").optional(),
  "environment": z.string().describe("Name of the Environment identifying a deployed Version to base the created Version on.").optional()
}
```

### set_deployment_datasets_id_environments_environment_id_post

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Dataset."),
  "environment_id": z.string().describe("Unique identifier for the Environment to deploy the Version to."),
  "version_id": z.string().describe("Unique identifier for the specific version of the Dataset.")
}
```

### remove_deployment_datasets_id_environments_environment_id_delete

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Dataset."),
  "environment_id": z.string().describe("Unique identifier for the Environment to remove the deployment from.")
}
```

### list_environments_datasets_id_environments_get

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Dataset.")
}
```

### log_evaluators_log_post

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "version_id": z.string().describe("ID of the Evaluator version to log against.").optional(),
  "environment": z.string().describe("Name of the Environment identifying a deployed version to log to.").optional(),
  "path": z.string().describe("Path of the Evaluator, including the name. This locates the Evaluator in the Humanloop filesystem and is used as as a unique identifier. For example: \`folder/name\` or just \`name\`.").optional(),
  "id": z.string().describe("ID for an existing Evaluator.").optional(),
  "start_time": z.string().datetime({ offset: true }).describe("When the logged event started.").optional(),
  "end_time": z.string().datetime({ offset: true }).describe("When the logged event ended.").optional(),
  "output": z.string().describe("Generated output from the LLM. Only populated for LLM Evaluator Logs.").optional(),
  "created_at": z.string().datetime({ offset: true }).describe("User defined timestamp for when the log was created. ").optional(),
  "error": z.string().describe("Error message if the log is an error.").optional(),
  "provider_latency": z.number().describe("Duration of the logged event in seconds.").optional(),
  "stdout": z.string().describe("Captured log and debug statements.").optional(),
  "provider_request": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nRaw request sent to provider. Only populated for LLM Evaluator Logs.").optional(),
  "provider_response": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nRaw response received the provider. Only populated for LLM Evaluator Logs.").optional(),
  "inputs": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nThe inputs passed to the prompt template.").optional(),
  "source": z.string().describe("Identifies where the model was called from.").optional(),
  "metadata": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nAny additional metadata to record.").optional(),
  "log_status": z.string().optional(),
  "parent_id": z.string().describe("Identifier of the evaluated Log. The newly created Log will have this one set as parent."),
  "source_datapoint_id": z.string().describe("Unique identifier for the Datapoint that this Log is derived from. This can be used by Humanloop to associate Logs to Evaluations. If provided, Humanloop will automatically associate this Log to Evaluations that require a Log for this Datapoint-Version pair.").optional(),
  "trace_parent_id": z.string().describe("The ID of the parent Log to nest this Log under in a Trace.").optional(),
  "user": z.string().describe("End-user ID related to the Log.").optional(),
  "b_environment": z.string().describe("The name of the Environment the Log is associated to.").optional(),
  "save": z.boolean().describe("Whether the request/response payloads will be stored on Humanloop.").optional(),
  "log_id": z.string().describe("This will identify a Log. If you don't provide a Log ID, Humanloop will generate one for you.").optional(),
  "output_message": z.string().optional(),
  "judgment": z.union([z.boolean(), z.string(), z.array(z.string()), z.number()]).describe("Evaluator assessment of the Log.").optional(),
  "marked_completed": z.boolean().describe("Whether the Log has been manually marked as completed by a user.").optional(),
  "spec": z.union([z.object({ "arguments_type": z.string(), "return_type": z.string(), "attributes": z.record(z.any()).describe("Additional fields to describe the Evaluator. Helpful to separate Evaluator versions from each other with details on how they were created or used.").optional(), "options": z.array(z.object({ "name": z.string().describe("The name of the option."), "valence": z.string().optional() })).describe("The options that can be applied as judgments. Only for Evaluators with \`return_type\` of 'boolean', 'select' or 'multi_select'.").optional(), "number_limits": z.string().optional(), "number_valence": z.string().optional(), "evaluator_type": z.literal("llm").describe("The type of the evaluator."), "prompt": z.string().optional() }), z.object({ "arguments_type": z.string(), "return_type": z.string(), "attributes": z.record(z.any()).describe("Additional fields to describe the Evaluator. Helpful to separate Evaluator versions from each other with details on how they were created or used.").optional(), "options": z.array(z.object({ "name": z.string().describe("The name of the option."), "valence": z.string().optional() })).describe("The options that can be applied as judgments. Only for Evaluators with \`return_type\` of 'boolean', 'select' or 'multi_select'.").optional(), "number_limits": z.string().optional(), "number_valence": z.string().optional(), "evaluator_type": z.literal("python").describe("The type of the evaluator."), "code": z.string().describe("The code for the Evaluator. This code will be executed in a sandboxed environment.") }), z.object({ "arguments_type": z.string(), "return_type": z.enum(["select","multi_select","text","number","boolean"]).describe("The type of the return value of the Evaluator."), "attributes": z.record(z.any()).describe("Additional fields to describe the Evaluator. Helpful to separate Evaluator versions from each other with details on how they were created or used.").optional(), "options": z.array(z.object({ "name": z.string().describe("The name of the option."), "valence": z.string().optional() })).describe("The options that can be applied as judgments.").optional(), "number_limits": z.string().optional(), "number_valence": z.string().optional(), "evaluator_type": z.literal("human").describe("The type of the evaluator."), "instructions": z.string().describe("Instructions and guidelines for applying judgments.").optional() }), z.object({ "arguments_type": z.string(), "return_type": z.string(), "attributes": z.record(z.any()).describe("Additional fields to describe the Evaluator. Helpful to separate Evaluator versions from each other with details on how they were created or used.").optional(), "options": z.array(z.object({ "name": z.string().describe("The name of the option."), "valence": z.string().optional() })).describe("The options that can be applied as judgments. Only for Evaluators with \`return_type\` of 'boolean', 'select' or 'multi_select'.").optional(), "number_limits": z.string().optional(), "number_valence": z.string().optional(), "evaluator_type": z.literal("external").describe("The type of the evaluator.") })]).optional()
}
```

### list_evaluators_get

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "page": z.number().int().gte(1).describe("Page offset for pagination.").optional(),
  "size": z.number().int().describe("Page size for pagination. Number of Evaluators to fetch.").optional(),
  "name": z.string().describe("Case-insensitive filter for Evaluator name.").optional(),
  "user_filter": z.string().describe("Case-insensitive filter for users in the Evaluator. This filter matches against both email address and name of users.").optional(),
  "sort_by": z.enum(["created_at","updated_at","name"]).describe("An enumeration.").describe("Field to sort Evaluators by").optional(),
  "order": z.enum(["asc","desc"]).describe("An enumeration.").describe("Direction to sort by.").optional()
}
```

### upsert_evaluators_post

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "path": z.string().describe("Path of the Evaluator, including the name. This locates the Evaluator in the Humanloop filesystem and is used as as a unique identifier. For example: \`folder/name\` or just \`name\`.").optional(),
  "id": z.string().describe("ID for an existing Evaluator.").optional(),
  "version_name": z.string().describe("Unique name for the Evaluator version. Version names must be unique for a given Evaluator.").optional(),
  "version_description": z.string().describe("Description of the version, e.g., the changes made in this version.").optional(),
  "spec": z.object({ "arguments_type": z.string(), "return_type": z.string(), "attributes": z.record(z.any()).describe("Additional fields to describe the Evaluator. Helpful to separate Evaluator versions from each other with details on how they were created or used.").optional(), "options": z.array(z.object({ "name": z.string().describe("The name of the option."), "valence": z.string().optional() })).describe("The options that can be applied as judgments. Only for Evaluators with \`return_type\` of 'boolean', 'select' or 'multi_select'.").optional(), "number_limits": z.string().optional(), "number_valence": z.string().optional(), "evaluator_type": z.literal("llm").describe("The type of the evaluator."), "prompt": z.string().optional() })
}
```

### get_evaluators_id_get

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Evaluator."),
  "version_id": z.string().describe("A specific Version ID of the Evaluator to retrieve.").optional(),
  "environment": z.string().describe("Name of the Environment to retrieve a deployed Version from.").optional()
}
```

### delete_evaluators_id_delete

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Evaluator.")
}
```

### move_evaluators_id_patch

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Evaluator."),
  "path": z.string().describe("Path of the Evaluator including the Evaluator name, which is used as a unique identifier.").optional(),
  "name": z.string().describe("Name of the Evaluator, which is used as a unique identifier.").optional()
}
```

### list_versions_evaluators_id_versions_get

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for the Evaluator."),
  "evaluator_aggregates": z.boolean().describe("Whether to include Evaluator aggregate results for the versions in the response").optional()
}
```

### delete_evaluator_version_evaluators_id_versions_version_id_delet

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Evaluator."),
  "version_id": z.string().describe("Unique identifier for the specific version of the Evaluator.")
}
```

### update_evaluator_version_evaluators_id_versions_version_id_patch

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Evaluator."),
  "version_id": z.string().describe("Unique identifier for the specific version of the Evaluator."),
  "name": z.string().describe("Name of the version.").optional(),
  "description": z.string().describe("Description of the version.").optional()
}
```

### set_deployment_evaluators_id_environments_environment_id_post

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Evaluator."),
  "environment_id": z.string().describe("Unique identifier for the Environment to deploy the Version to."),
  "version_id": z.string().describe("Unique identifier for the specific version of the Evaluator.")
}
```

### remove_deployment_evaluators_id_environments_environment_id_dele

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Evaluator."),
  "environment_id": z.string().describe("Unique identifier for the Environment to remove the deployment from.")
}
```

### list_environments_evaluators_id_environments_get

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Evaluator.")
}
```

### update_monitoring_evaluators_id_evaluators_post

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string(),
  "activate": z.array(z.union([z.object({ "evaluator_version_id": z.string().describe("Unique identifier for the Evaluator Version to be used for monitoring.") }), z.object({ "evaluator_id": z.string().describe("Unique identifier for the Evaluator to be used for monitoring."), "environment_id": z.string().describe("Unique identifier for the Environment. The Evaluator Version deployed to this Environment will be used for monitoring.") })])).describe("Evaluators to activate for Monitoring. These will be automatically run on new Logs.").optional(),
  "deactivate": z.array(z.union([z.object({ "evaluator_version_id": z.string().describe("Unique identifier for the Evaluator Version to be used for monitoring.") }), z.object({ "evaluator_id": z.string().describe("Unique identifier for the Evaluator to be used for monitoring."), "environment_id": z.string().describe("Unique identifier for the Environment. The Evaluator Version deployed to this Environment will be used for monitoring.") })])).describe("Evaluators to deactivate. These will not be run on new Logs.").optional()
}
```

### log_flows_log_post

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "version_id": z.string().describe("A specific Version ID of the Flow to log to.").optional(),
  "environment": z.string().describe("Name of the Environment identifying a deployed version to log to.").optional(),
  "messages": z.array(z.object({ "content": z.union([z.string(), z.array(z.union([z.object({ "type": z.literal("text"), "text": z.string().describe("The message's text content.") }), z.object({ "type": z.literal("image_url"), "image_url": z.string() })]))]).nullable().describe("The content of the message.").optional(), "name": z.string().nullable().describe("Optional name of the message author.").optional(), "tool_call_id": z.string().nullable().describe("Tool call that this message is responding to.").optional(), "role": z.string(), "tool_calls": z.array(z.object({ "id": z.string(), "type": z.literal("function").describe("The type of tool to call."), "function": z.object({ "name": z.string(), "arguments": z.string().optional() }).describe("A function tool to be called by the model where user owns runtime.") }).describe("A tool call to be made.")).nullable().describe("A list of tool calls requested by the assistant.").optional() })).describe("List of chat messages that were used as an input to the Flow.").optional(),
  "output_message": z.string().optional(),
  "run_id": z.string().describe("Unique identifier for the Run to associate the Log to.").optional(),
  "path": z.string().describe("Path of the Flow, including the name. This locates the Flow in the Humanloop filesystem and is used as as a unique identifier. For example: \`folder/name\` or just \`name\`.").optional(),
  "id": z.string().describe("ID for an existing Flow.").optional(),
  "start_time": z.string().datetime({ offset: true }).describe("The start time of the Trace. Will be updated if a child Log with an earlier start time is added.").optional(),
  "end_time": z.string().datetime({ offset: true }).describe("The end time of the Trace. Will be updated if a child Log with a later end time is added.").optional(),
  "output": z.string().describe("Generated output from your model for the provided inputs. Can be \`None\` if logging an error, or if creating a parent Log with the intention to populate it later.").optional(),
  "created_at": z.string().datetime({ offset: true }).describe("User defined timestamp for when the log was created. ").optional(),
  "error": z.string().describe("Error message if the log is an error.").optional(),
  "provider_latency": z.number().describe("Duration of the logged event in seconds.").optional(),
  "stdout": z.string().describe("Captured log and debug statements.").optional(),
  "provider_request": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nRaw request sent to provider.").optional(),
  "provider_response": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nRaw response received the provider.").optional(),
  "inputs": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nThe inputs passed to the prompt template.").optional(),
  "source": z.string().describe("Identifies where the model was called from.").optional(),
  "metadata": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nAny additional metadata to record.").optional(),
  "log_status": z.string().optional(),
  "source_datapoint_id": z.string().describe("Unique identifier for the Datapoint that this Log is derived from. This can be used by Humanloop to associate Logs to Evaluations. If provided, Humanloop will automatically associate this Log to Evaluations that require a Log for this Datapoint-Version pair.").optional(),
  "trace_parent_id": z.string().describe("The ID of the parent Log to nest this Log under in a Trace.").optional(),
  "user": z.string().describe("End-user ID related to the Log.").optional(),
  "b_environment": z.string().describe("The name of the Environment the Log is associated to.").optional(),
  "save": z.boolean().describe("Whether the request/response payloads will be stored on Humanloop.").optional(),
  "log_id": z.string().describe("This will identify a Log. If you don't provide a Log ID, Humanloop will generate one for you.").optional(),
  "flow": z.string().optional()
}
```

### update_log_flows_logs_log_id_patch

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "log_id": z.string().describe("Unique identifier of the Flow Log."),
  "messages": z.array(z.object({ "content": z.union([z.string(), z.array(z.union([z.object({ "type": z.literal("text"), "text": z.string().describe("The message's text content.") }), z.object({ "type": z.literal("image_url"), "image_url": z.string() })]))]).nullable().describe("The content of the message.").optional(), "name": z.string().nullable().describe("Optional name of the message author.").optional(), "tool_call_id": z.string().nullable().describe("Tool call that this message is responding to.").optional(), "role": z.string(), "tool_calls": z.array(z.object({ "id": z.string(), "type": z.literal("function").describe("The type of tool to call."), "function": z.object({ "name": z.string(), "arguments": z.string().optional() }).describe("A function tool to be called by the model where user owns runtime.") }).describe("A tool call to be made.")).nullable().describe("A list of tool calls requested by the assistant.").optional() })).describe("List of chat messages that were used as an input to the Flow.").optional(),
  "output_message": z.string().optional(),
  "inputs": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nThe inputs passed to the Flow Log.").optional(),
  "output": z.string().describe("The output of the Flow Log. Provide None to unset existing \`output\` value. Provide either this, \`output_message\` or \`error\`.").optional(),
  "error": z.string().describe("The error message of the Flow Log. Provide None to unset existing \`error\` value. Provide either this, \`output_message\` or \`output\`.").optional(),
  "log_status": z.string().optional()
}
```

### get_flows_id_get

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Flow."),
  "version_id": z.string().describe("A specific Version ID of the Flow to retrieve.").optional(),
  "environment": z.string().describe("Name of the Environment to retrieve a deployed Version from.").optional()
}
```

### delete_flows_id_delete

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Flow.")
}
```

### move_flows_id_patch

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Flow."),
  "path": z.string().describe("Path of the Flow including the Flow name, which is used as a unique identifier.").optional(),
  "name": z.string().describe("Name of the Flow.").optional(),
  "directory_id": z.string().describe("Unique identifier for the Directory to move Flow to. Starts with \`dir_\`.").optional()
}
```

### list_flows_get

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "page": z.number().int().gte(1).describe("Page number for pagination.").optional(),
  "size": z.number().int().gte(0).describe("Page size for pagination. Number of Flows to fetch.").optional(),
  "name": z.string().describe("Case-insensitive filter for Flow name.").optional(),
  "user_filter": z.string().describe("Case-insensitive filter for users in the Flow. This filter matches against both email address and name of users.").optional(),
  "sort_by": z.enum(["created_at","updated_at","name"]).describe("An enumeration.").describe("Field to sort Flows by").optional(),
  "order": z.enum(["asc","desc"]).describe("An enumeration.").describe("Direction to sort by.").optional()
}
```

### upsert_flows_post

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "path": z.string().describe("Path of the Flow, including the name. This locates the Flow in the Humanloop filesystem and is used as as a unique identifier. For example: \`folder/name\` or just \`name\`.").optional(),
  "id": z.string().describe("ID for an existing Flow.").optional(),
  "attributes": z.record(z.any()).describe("[EXPANDABLE PARAMETER]:\nA key-value object identifying the Flow Version."),
  "version_name": z.string().describe("Unique name for the Flow version. Version names must be unique for a given Flow.").optional(),
  "version_description": z.string().describe("Description of the version, e.g., the changes made in this version.").optional()
}
```

### list_versions_flows_id_versions_get

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Flow."),
  "evaluator_aggregates": z.boolean().describe("Whether to include Evaluator aggregate results for the versions in the response").optional()
}
```

### delete_flow_version_flows_id_versions_version_id_delete

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Flow."),
  "version_id": z.string().describe("Unique identifier for the specific version of the Flow.")
}
```

### update_flow_version_flows_id_versions_version_id_patch

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Flow."),
  "version_id": z.string().describe("Unique identifier for the specific version of the Flow."),
  "name": z.string().describe("Name of the version.").optional(),
  "description": z.string().describe("Description of the version.").optional()
}
```

### set_deployment_flows_id_environments_environment_id_post

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Flow."),
  "environment_id": z.string().describe("Unique identifier for the Environment to deploy the Version to."),
  "version_id": z.string().describe("Unique identifier for the specific version of the Flow.")
}
```

### remove_deployment_flows_id_environments_environment_id_delete

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Flow."),
  "environment_id": z.string().describe("Unique identifier for the Environment to remove the deployment from.")
}
```

### list_environments_flows_id_environments_get

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Flow.")
}
```

### update_monitoring_flows_id_evaluators_post

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string(),
  "activate": z.array(z.union([z.object({ "evaluator_version_id": z.string().describe("Unique identifier for the Evaluator Version to be used for monitoring.") }), z.object({ "evaluator_id": z.string().describe("Unique identifier for the Evaluator to be used for monitoring."), "environment_id": z.string().describe("Unique identifier for the Environment. The Evaluator Version deployed to this Environment will be used for monitoring.") })])).describe("Evaluators to activate for Monitoring. These will be automatically run on new Logs.").optional(),
  "deactivate": z.array(z.union([z.object({ "evaluator_version_id": z.string().describe("Unique identifier for the Evaluator Version to be used for monitoring.") }), z.object({ "evaluator_id": z.string().describe("Unique identifier for the Evaluator to be used for monitoring."), "environment_id": z.string().describe("Unique identifier for the Environment. The Evaluator Version deployed to this Environment will be used for monitoring.") })])).describe("Evaluators to deactivate. These will not be run on new Logs.").optional()
}
```

### list_directories_get

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{}
```

### create_directories_post

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "name": z.string().describe("Name of the directory to create.").optional(),
  "parent_id": z.string().describe("ID of the parent directory. Starts with \`dir_\`.").optional(),
  "path": z.string().describe("Path to create the directory in, relative to the root directory. If the path does not exist, it will be created. Includes name, e.g. \`path/to/directory\`.").optional()
}
```

### get_directories_id_get

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("String ID of directory. Starts with \`dir_\`.")
}
```

### delete_directories_id_delete

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Directory. Starts with \`dir_\`.")
}
```

### update_directories_id_patch

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Directory. Starts with \`dir_\`."),
  "name": z.string().describe("Name to set for the directory.").optional(),
  "parent_id": z.string().describe("ID of the parent directory. Specify this to move directories. Starts with \`dir_\`.").optional(),
  "path": z.string().describe("Path to move the directory to, relative to the root directory. Specify this to move directories. Includes name, e.g. \`path/to/directory\`.").optional()
}
```

### list_files_files_get

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "page": z.number().int().gte(1).describe("Page offset for pagination.").optional(),
  "size": z.number().int().gte(0).describe("Page size for pagination. Number of files to fetch.").optional(),
  "name": z.string().describe("Case-insensitive filter for file name.").optional(),
  "template": z.boolean().describe("Filter to include only template files.").optional(),
  "type": z.array(z.enum(["prompt","tool","dataset","evaluator","flow"]).describe("Enum for File types.")).describe("List of file types to filter for.").optional(),
  "environment": z.string().describe("Case-sensitive filter for files with a deployment in the specified environment. Requires the environment name.").optional(),
  "sort_by": z.enum(["created_at","updated_at","name"]).describe("An enumeration.").describe("Field to sort files by").optional(),
  "order": z.enum(["asc","desc"]).describe("An enumeration.").describe("Direction to sort by.").optional()
}
```

### retrieve_by_path_files_retrieve_by_path_post

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "environment": z.string().describe("Name of the Environment to retrieve a deployed Version from.").optional(),
  "path": z.string().describe("Path of the File to retrieve.")
}
```

### list_evaluations_get

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "file_id": z.string().describe("Filter by File ID. Only Evaluations for the specified File will be returned."),
  "page": z.number().int().gte(1).describe("Page number for pagination.").optional(),
  "size": z.number().int().gte(0).describe("Page size for pagination. Number of Evaluations to fetch.").optional()
}
```

### create_evaluations_post

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "file": z.string().optional(),
  "name": z.string().describe("Name of the Evaluation to help identify it. Must be unique within the associated File.").optional(),
  "evaluators": z.array(z.union([z.object({ "version_id": z.string().describe("Unique identifier for the Version."), "orchestrated": z.boolean().describe("Whether the Evaluator is orchestrated by Humanloop. Default is \`True\`. If \`False\`, a log for the Evaluator should be submitted by the user via the API.") }).describe("Base model for specifying an Evaluator for an Evaluation."), z.object({ "environment": z.string().describe("If provided, the Version deployed to this Environment is used. If not provided, the Version deployed to the default Environment is used.").optional(), "id": z.string().describe("Unique identifier for the File."), "orchestrated": z.boolean().describe("Whether the Evaluator is orchestrated by Humanloop. Default is \`True\`. If \`False\`, a log for the Evaluator should be submitted by the user via the API.") }).describe("Base model for specifying an Evaluator for an Evaluation."), z.object({ "environment": z.string().describe("If provided, the Version deployed to this Environment is used. If not provided, the Version deployed to the default Environment is used.").optional(), "path": z.string().describe("Path identifying a File. Provide this to specify a File."), "orchestrated": z.boolean().describe("Whether the Evaluator is orchestrated by Humanloop. Default is \`True\`. If \`False\`, a log for the Evaluator should be submitted by the user via the API.") }).describe("Base model for specifying an Evaluator for an Evaluation.")])).describe("The Evaluators used to evaluate.")
}
```

### add_evaluators_evaluations_id_evaluators_post

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Evaluation."),
  "evaluators": z.array(z.union([z.object({ "version_id": z.string().describe("Unique identifier for the Version."), "orchestrated": z.boolean().describe("Whether the Evaluator is orchestrated by Humanloop. Default is \`True\`. If \`False\`, a log for the Evaluator should be submitted by the user via the API.") }).describe("Base model for specifying an Evaluator for an Evaluation."), z.object({ "environment": z.string().describe("If provided, the Version deployed to this Environment is used. If not provided, the Version deployed to the default Environment is used.").optional(), "id": z.string().describe("Unique identifier for the File."), "orchestrated": z.boolean().describe("Whether the Evaluator is orchestrated by Humanloop. Default is \`True\`. If \`False\`, a log for the Evaluator should be submitted by the user via the API.") }).describe("Base model for specifying an Evaluator for an Evaluation."), z.object({ "environment": z.string().describe("If provided, the Version deployed to this Environment is used. If not provided, the Version deployed to the default Environment is used.").optional(), "path": z.string().describe("Path identifying a File. Provide this to specify a File."), "orchestrated": z.boolean().describe("Whether the Evaluator is orchestrated by Humanloop. Default is \`True\`. If \`False\`, a log for the Evaluator should be submitted by the user via the API.") }).describe("Base model for specifying an Evaluator for an Evaluation.")])).describe("The Evaluators to add to this Evaluation.")
}
```

### remove_evaluator_evaluations_id_evaluators_evaluator_version_id_

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Evaluation."),
  "evaluator_version_id": z.string().describe("Unique identifier for Evaluator Version.")
}
```

### get_evaluations_id_get

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Evaluation.")
}
```

### delete_evaluations_id_delete

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Evaluation.")
}
```

### list_runs_for_evaluation_evaluations_id_runs_get

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Evaluation.")
}
```

### create_run_evaluations_id_runs_post

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Evaluation."),
  "dataset": z.union([z.object({ "version_id": z.string().describe("Unique identifier for the Version.") }), z.object({ "environment": z.string().describe("If provided, the Version deployed to this Environment is used. If not provided, the Version deployed to the default Environment is used.").optional(), "id": z.string().describe("Unique identifier for the File.") }).describe("Specification of a File by its ID."), z.object({ "environment": z.string().describe("If provided, the Version deployed to this Environment is used. If not provided, the Version deployed to the default Environment is used.").optional(), "path": z.string().describe("Path identifying a File. Provide this to specify a File.") }).describe("Specification of a File by its path.")]).describe("Dataset to use in this Run.").optional(),
  "version": z.union([z.object({ "version_id": z.string().describe("Unique identifier for the Version.") }), z.object({ "environment": z.string().describe("If provided, the Version deployed to this Environment is used. If not provided, the Version deployed to the default Environment is used.").optional(), "id": z.string().describe("Unique identifier for the File.") }).describe("Specification of a File by its ID."), z.object({ "environment": z.string().describe("If provided, the Version deployed to this Environment is used. If not provided, the Version deployed to the default Environment is used.").optional(), "path": z.string().describe("Path identifying a File. Provide this to specify a File.") }).describe("Specification of a File by its path.")]).describe("Version to use in this Run.").optional(),
  "orchestrated": z.boolean().describe("Whether the Run is orchestrated by Humanloop. If \`True\`, Humanloop will generate Logs for the Run; \`dataset\` and \`version\` must be provided. If \`False\`, a log for the Prompt/Tool should be submitted by the user via the API.").optional(),
  "use_existing_logs": z.boolean().describe("If \`True\`, the Run will be initialized with existing Logs associated with the Dataset and Version. If \`False\`, the Run will be initialized with no Logs. Can only be set to \`True\` when both \`dataset\` and \`version\` are provided.").optional()
}
```

### add_existing_run_evaluations_id_runs_run_id_post

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Evaluation."),
  "run_id": z.string().describe("Unique identifier for Run.")
}
```

### remove_run_evaluations_id_runs_run_id_delete

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Evaluation."),
  "run_id": z.string().describe("Unique identifier for Run.")
}
```

### update_evaluation_run_evaluations_id_runs_run_id_patch

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Evaluation."),
  "run_id": z.string().describe("Unique identifier for Run."),
  "control": z.literal(true).describe("If \`True\`, this Run will be used as the control in the Evaluation. Stats for other Runs will be compared to this Run. This will replace any existing control Run.").optional(),
  "status": z.string().optional()
}
```

### add_logs_to_run_evaluations_id_runs_run_id_logs_post

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Evaluation."),
  "run_id": z.string().describe("Unique identifier for Run."),
  "log_ids": z.array(z.string()).describe("The IDs of the Logs to add to the Run.")
}
```

### get_stats_evaluations_id_stats_get

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Evaluation.")
}
```

### get_logs_evaluations_id_logs_get

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("String ID of evaluation. Starts with \`ev_\` or \`evr_\`."),
  "page": z.number().int().gte(1).describe("Page number for pagination.").optional(),
  "size": z.number().int().gte(0).describe("Page size for pagination. Number of Logs to fetch.").optional(),
  "run_id": z.array(z.string()).describe("Filter by Run IDs. Only Logs for the specified Runs will be returned.").optional()
}
```

### list_logs_get

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "file_id": z.string().describe("Unique identifier for the File to list Logs for."),
  "page": z.number().int().gte(1).describe("Page number for pagination.").optional(),
  "size": z.number().int().gte(0).describe("Page size for pagination. Number of Logs to fetch.").optional(),
  "version_id": z.string().describe("If provided, only Logs belonging to the specified Version will be returned.").optional(),
  "version_status": z.enum(["uncommitted","committed","deleted"]).describe("An enumeration.").describe("If provided, only Logs belonging to Versions with the specified status will be returned.").optional(),
  "id": z.array(z.string()).describe("If provided, returns Logs whose IDs contain any of the specified values as substrings.").optional(),
  "search": z.string().describe("If provided, only Logs that contain the provided string in its inputs and output will be returned.").optional(),
  "metadata_search": z.string().describe("If provided, only Logs that contain the provided string in its metadata will be returned.").optional(),
  "start_date": z.union([z.string().datetime({ offset: true }), z.string().date()]).describe("If provided, only Logs created after the specified date will be returned.").optional(),
  "end_date": z.union([z.string().datetime({ offset: true }), z.string().date()]).describe("If provided, only Logs created before the specified date will be returned.").optional(),
  "include_parent": z.boolean().describe("If true, include the full parent Log in the response. Only applicable when retrieving Evaluator Logs.").optional(),
  "in_trace_filter": z.array(z.boolean()).describe("If true, return Logs that are associated to a Trace. False, return Logs that are not associated to a Trace.").optional(),
  "sample": z.number().int().gte(0).describe("If provided, limit the response to a random subset of logs from the filtered results. (This will be an approximate sample, not a strict limit.)").optional(),
  "include_trace_children": z.boolean().describe("If true, populate \`trace_children\` for the retrieved Logs. Only applicable when retrieving Flow Logs.").optional()
}
```

### logs_delete

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.array(z.string()).describe("Unique identifiers for the Logs to delete.")
}
```

### get_logs_id_get

**Environment variables**

- `X_API_KEY`

**Input schema**

```ts
{
  "id": z.string().describe("Unique identifier for Log.")
}
```
