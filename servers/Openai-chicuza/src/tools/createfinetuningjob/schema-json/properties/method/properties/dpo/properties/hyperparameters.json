{
  "type": "object",
  "description": "The hyperparameters used for the fine-tuning job.",
  "properties": {
    "beta": {
      "description": "The beta value for the DPO method. A higher beta value will increase the weight of the penalty between the policy and reference model.\n",
      "default": "auto",
      "anyOf": [
        {
          "type": "string",
          "enum": [
            "auto"
          ],
          "x-stainless-const": true
        }
      ]
    },
    "batch_size": {
      "description": "Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance.\n",
      "default": "auto",
      "anyOf": [
        {
          "type": "string",
          "enum": [
            "auto"
          ],
          "x-stainless-const": true
        }
      ]
    },
    "learning_rate_multiplier": {
      "description": "Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.\n",
      "default": "auto",
      "anyOf": [
        {
          "type": "string",
          "enum": [
            "auto"
          ],
          "x-stainless-const": true
        }
      ]
    },
    "n_epochs": {
      "description": "The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.\n",
      "default": "auto",
      "anyOf": [
        {
          "type": "string",
          "enum": [
            "auto"
          ],
          "x-stainless-const": true
        }
      ]
    }
  }
}